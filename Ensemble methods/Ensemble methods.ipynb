{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivacija\n",
    "\n",
    "\n",
    "Pretpostavimo da ste filmski redatelj i napravili ste kratki film o vrlo važnoj i zanimljivoj temi. Prije objavljivanja filma želite dobiti povratne informacije (ocjene). Koji su mogući načini na koje to možete učiniti?\n",
    "\n",
    "\n",
    "**1.** *Možete zamoliti nekog od vaših prijatelja da ocijeni vaš film.*  \n",
    "Sasvim je moguće da vas osoba koju ste odabrali jako voli i ne želi vam slomiti srce davajući lošu ocjenu.\n",
    "\n",
    "\n",
    "**2.** *Drugi način može biti ako zamolite 5 vaših kolega da ocijene film.*  \n",
    "Ovaj način bi trebao pružiti bolju ideju o filmu odnosno može dati poštene ocjene za film, no problem i dalje postoji. Ovih 5 osoba možda neće biti “stručnjaci za temu” vašeg filma. Naravno, mogli bi razumjeti kinematografiju, snimke ili zvuk, ali u isto vrijeme možda i nisu najbolji suci tamnog humora.\n",
    "\n",
    "\n",
    "**3.** *Kako bi bilo da zamolite 50 ljudi da ocijene film?*  \n",
    "Neki od njih mogu biti vaši prijatelji, neki od njih mogu biti vaši kolege, a neki čak i potpuni stranci.\n",
    "\n",
    "Odgovori bi, u ovom slučaju, bili općenitiji i raznolikiji jer sada imate ljude s različitim skupinama vještina. I kako se ispostavilo - ovo je bolji pristup za dobivanje poštenih ocjena od prethodnih slučajeva koje smo vidjeli.\n",
    "\n",
    "Pomoću ovih primjera možete zaključiti da će raznolika skupina ljudi vjerojatno donijeti bolje odluke u odnosu na pojedince. Slično vrijedi i za različite modele u usporedbi s pojedinim modelima. Ova raznolikost u strojnom učenju postiže se tehnikom nazvanom Ensemble Learning.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prije početka potrebno je ponoviti nekoliko osnovnih pojmova:\n",
    "\n",
    "---\n",
    "### Varijanca (engl. *variance*)\n",
    "Očekivano kvadratno odstupanje slučajne varijable od njezine srednje vrijednosti. Dana je formulom: $$\\sigma^2 = \\frac{\\sum(x - \\mu)^2}{N}$$ gdje je: \n",
    " - $\\sigma^2$ varijanca\n",
    " - $x$ vrijednost slučajne varijable\n",
    " - $\\mu$ aritmetička sredina podataka\n",
    " - $N$ broj opservacija\n",
    " \n",
    " \n",
    " \n",
    "### Sistemska pogreška procjenitelja (engl. *bias of an estimator*)\n",
    "Razlika između očekivane vrijednosti procjenitelja i stvarne vrijednosti parametra koji se procjenjuje.\n",
    "\n",
    "\n",
    "\n",
    "### Bootstraping \n",
    "Odvija se na sljedeći način: Neka imamo uzorak $X$ veličine $N$. Možemo napraviti novi uzorak iz izvornog uzorka izvlačenjem $N$ elemenata iz posljednjeg uzorka nasumično i jednoliko, uz zamjenu. Drugim riječima, odabiremo slučajni element iz izvornog uzorka veličine $N$ i to $N$ puta. Jednako je vjerojatno da će svi elementi biti odabrani, tako da je svaki element odabran s jednakom vjerojatnošću $\\frac{1}{N}$. \n",
    " \n",
    "Recimo da izvlačimo kuglice iz vrećice jednu po jednu. U svakom koraku se odabrana kuglica se vraća natrag u vrećicu tako da je sljedeći odabir izveden sa jednakom vjerojatnošću, tj. iz istog broja kuglica $N$. Potrebno je imati na umu da, budući da se kuglice vraćaju, se mogu pojaviti duplikati u novom uzorku. Nazovimo ovaj novi uzorak $X_1$.\n",
    "\n",
    "Ponavljajući ovu proceduru $M$ puta, kreiramo $M$ *bootstrap* uzoraka $X1,…, XM$. Na kraju, imamo dovoljan broj uzoraka i možemo izračunati različite statistike izvorne distribucije.\n",
    "\n",
    "<div style=\"width:70%;margin:0 auto;\">![Boostraping.png](img/boostraping.png)</div>\n",
    " \n",
    "---\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Općenito\n",
    "\n",
    "\n",
    "Cilj orkestriranih metoda (engl. *Ensemble methods*) je kombinirati predviđanja nekoliko osnovnih procjenitelja (engl. *estimators*) izgrađenih s danim algoritmom učenja kako bi se poboljšala generalizabilnost / robustnost u usporedbi sa jednim procjeniteljem.\n",
    "\n",
    "<div style=\"width:90%;margin:0 auto;\">![ensemble_machine_learning.png](img/ensemble_machine_learning.png)</div>\n",
    "\n",
    "---\n",
    "Obično se razlikuju dvije obitelji *ensemble* metoda:\n",
    "\n",
    "- **Averaging methods**: glavni princip je izgradnja nekoliko neovisnih procjenitelja iz kojih se kod predviđanja izračunava srednja vrijednost. Kombinirani procjenitelji su u prosjeku bolji nego bilo koji pojedinačni procjenitelj jer je njegova varijanca smanjena.\n",
    "\n",
    "\n",
    "- **Boosting methods**: bazni procjenitelji se slijedno izgrađuju pokušavajući smanjiti sistemsku pogrešku (*bias*) kombiniranog procjenitelja. Motivacija je kombinirati nekoliko slabih modela kako bi se izgradio snažan procjenitelj.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Tri najpopularnije metode za kombiniranje predviđanja različitih modela su:\n",
    "\n",
    "- **Voting methods**: glavni princip je izgradnja nekoliko neovisnih procjenitelja, tipično različitih tipova, koji predviđanjem vrijednosti daju *glas* toj vrijednosti.\n",
    "\n",
    "\n",
    "- **Bagging methods**: Izgradnja višestrukih modela (obično istog tipa) iz različitih poduzoraka niza podataka za trening. \n",
    "\n",
    "\n",
    "- **Boostring methods**: Izgradnja više modela (obično istog tipa) od kojih svaki uči popraviti pogreške predviđanja prethodnog modela u lancu.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset koji će se koristiti kod primjera\n",
    "\n",
    "---\n",
    "\n",
    "Dataset se može preuzeti i [ovdje](https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/) (potrebna registracija)\n",
    "\n",
    "\n",
    "<pre>\n",
    "<span style=\"border-bottom: 1px solid #d8d8d8;display: inline-block;width: 501px;\"><b>Variable</b>           Description</span>\n",
    "<b>Loan_ID</b>            Unique Loan ID\n",
    "<b>Gender</b>             Male/ Female\n",
    "<b>Married</b>            Applicant married (Y/N)\n",
    "<b>Dependents</b>         Number of dependents\n",
    "<b>Education</b>          Applicant Education (Graduate/ Under Graduate)\n",
    "<b>Self_Employed</b>      Self employed (Y/N)\n",
    "<b>ApplicantIncome</b>    Applicant income\n",
    "<b>CoapplicantIncome</b>  Coapplicant income\n",
    "<b>LoanAmount</b>         Loan amount in thousands\n",
    "<b>Loan_Amount_Term</b>   Term of loan in months\n",
    "<b>Credit_History</b>     credit history meets guidelines\n",
    "<b>Property_Area</b>      Urban/ Semi Urban/ Rural\n",
    "<b>Loan_Status</b>        Loan approved (Y/N)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Učitaj dataset\n",
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "# Loan_ID je jedinstven pa samim time ne pridonosi modelu\n",
    "dataset = dataset.drop(labels=\"Loan_ID\", axis=1, inplace=False)\n",
    "\n",
    "# Popunjavanje nedostajućih vrijednosti\n",
    "dataset['Gender'] = dataset['Gender'].fillna('Male')\n",
    "dataset['Married'] = dataset['Married'].fillna('Yes')\n",
    "dataset['Dependents'] = dataset['Dependents'].fillna('0')\n",
    "dataset['Self_Employed'] = dataset['Self_Employed'].fillna('No')\n",
    "dataset['LoanAmount'] = dataset['LoanAmount'].fillna(dataset['LoanAmount'].mean())\n",
    "dataset['Loan_Amount_Term'] = dataset['Loan_Amount_Term'].fillna(360.0)\n",
    "dataset['Credit_History'] = dataset['Credit_History'].fillna(1.0)\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "x_train = train.drop('Loan_Status', axis=1)\n",
    "y_train = train['Loan_Status']\n",
    "\n",
    "x_test = test.drop('Loan_Status', axis=1)\n",
    "y_test = test['Loan_Status']\n",
    "\n",
    "# one-hot encoding\n",
    "x_train = pd.get_dummies(x_train)\n",
    "x_test = pd.get_dummies(x_test)\n",
    "\n",
    "\n",
    "x_train_r = train.drop('LoanAmount', axis=1)\n",
    "y_train_r = train['LoanAmount']\n",
    "\n",
    "x_test_r = test.drop('LoanAmount', axis=1)\n",
    "y_test_r = test['LoanAmount']\n",
    "\n",
    "# one-hot encoding\n",
    "x_train_r = pd.get_dummies(x_train_r)\n",
    "x_test_r = pd.get_dummies(x_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Voting Classifier\n",
    "\n",
    "Ideja iza *VotingClassifier*-a je kombinirati konceptualno različite klasifikatore i koristiti većinski glas ili srednju predviđenu vjerojatnost (*soft vote*) da bi se predvidjele klase. Takav klasifikator može biti koristan za skup klasifikatora sa sličnim performansama kako bi se izjednačile slabosti pojedinačnih klasifikatora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Major Class Labels (Major/Hard Voting)\n",
    "\n",
    "\n",
    "U većinskom glasanju, predviđena klasa za pojedini uzorak je klasa koja predstavlja većinu (**mod**) predviđenih klasa od svakog pojedinog klasifikatora\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2 Weighted Average Probabilities (Soft Voting)\n",
    "\n",
    "Za razliku od većinskog glasanja (*hard voting*), *soft voting* vraća klasu koja proizlazi kao maksimum od sume predviđenih vjerojatnosti. Specifične težine se mogu dodijeliti svakom klasifikatoru kroz `weights` parametar. Kada su težine dodijeljene, prikupljaju se vjerojatnosti klase za svaki klasifikator, množe se sa njegovom težinom i zatim izračunata prosječna vrijednost. Konačna klasa je izvedena iz klase sa najvećom prosječnom vjerojatnosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7967479674796748"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='soft', weights=[2,1])\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2.Bagging methods\n",
    "\n",
    "Pretpostavimo da imamo skup $X$ za treniranje. Koristeći *bootstrapping* generiramo uzorke $X1,…, XM$. Sada, za svaki taj uzorak, treniramo vlastiti klasifikator $a_i(x)$. Konačni klasifikator će izračunati prosjek izlaza iz svih tih pojedinačnih klasifikatora. U slučaju klasifikacije, ova tehnika koristi glasovanje dano formulom: $a(x) = \\frac{1}{M} \\sum a_i(x)$\n",
    "\n",
    "\n",
    "<div style=\"width:70%;margin:0 auto;\">![bagging.png](img/bagging.png)</div>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 2.1 Bagging meta-estimator\n",
    "\n",
    "\n",
    "Bagging meta-estimator je *ensembling* algoritam koji se može koristiti i za klasifikacijske (BaggingClassifier) i regresijske (BaggingRegressor) probleme. Slijedi tipične *bagging* tehnike kako bi se napravila predviđanja.\n",
    "\n",
    "U nastavku slijede koraci za *bagging meta-estimator* algoritam:\n",
    "\n",
    "1. Stvaraju se slučajni podskupovi iz izvornog skupa podataka (bootstrapping).\n",
    "2. Podskup skupa podataka uključuje sve značajke.\n",
    "3. Na svakom od ovih manjih skupova izgrađen je, korisnički određen, bazni procjenitelj.\n",
    "4. Predviđanja iz svakog modela se kombiniraju kako bi se dobio konačni rezultat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73983739837398377"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging meta-estimator\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1), random_state=1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25271636220069549"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging meta-estimator - kod za regresijski problem\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "model = BaggingRegressor(tree.DecisionTreeRegressor(random_state=1), random_state=1)\n",
    "model.fit(x_train_r, y_train_r)\n",
    "model.score(x_test_r, y_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Random forest\n",
    "\n",
    "Random Forest je još jedan algoritam strojnog učenja koji slijedi *bagging* tehniku. To je proširenje *bagging meta-estimator* algoritma. Osnovni procjenitelji u *random forest*-u su stabla odlučivanja. Za razliku od *bagging meta-estimator*, *random forest* nasumično odabire skup značajki koje se koriste za određivanje najbolje podjele na svakom čvoru stabla odlučivanja. \n",
    "\n",
    "\n",
    "Ako ga gledamo korak po korak, ovo *random forest* model radi:\n",
    "\n",
    "1. Stvaraju se slučajni podskupovi iz izvornog skupa podataka (bootstrapping).\n",
    "2. Na svakom čvoru u stablu odlučivanja smatra se da slučajni skup značajki odlučuje o najboljoj podjeli.\n",
    "3. Na svakom podskupu je ugrađen model stabla odlučivanja.\n",
    "4. Konačno predviđanje izračunava se prosječnim predviđanjima svih stabala odlučivanja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76422764227642281"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2828047197585537"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest - kod za regresijski problem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(random_state=1)\n",
    "model.fit(x_train_r, y_train_r)\n",
    "model.score(x_test_r, y_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Boosting methods\n",
    "\n",
    "\n",
    "*Boosting ensemble* algoritmi kreiraju niz modela koji pokušavaju ispraviti pogreške prethodnog modela u nizu. Kada se modeli izgrade, naprave se predikcije koje mogu biti težinski skalirane prema točnosti modela, naposljetku se rezultati kombiniraju kako bi se stvorilo konačno predviđanje izlaza.\n",
    "\n",
    "1. Kreira se podskup iz izvornog skupa podataka\n",
    "2. Inicijalno su svim točkama dodijeljene jednake težine\n",
    "3. Kreira se bazni model na tom podskupu\n",
    "4. Ovaj se model koristi za predikciju cijelog skupa podataka\n",
    "<div style=\"width:70%;margin:10px auto;\">![boosting_1.png](img/boosting_1.png)</div>\n",
    "5. Izračunavaju se pogreške koristeći stvarne i predviđene vrijednosti\n",
    "6. Nepravilno predviđenim opservacijama se težine povećavaju (ovdje će tri pogrešno klasificirane plave plus točke dobiti veću težinu)\n",
    "7. Kreira se drugi model i rade se predikcije na skupu podataka (ovaj model pokušava ispraviti pogreške iz prethodnog modela)\n",
    "<div style=\"width:70%;margin:10px auto;\">![boosting_2.png](img/boosting_2.png)</div>\n",
    "8. Slično tome, kreira se više modela, svaki ispravljajući pogreške prethodnog modela.\n",
    "9. Konačni model (snažan učenik) je aritmetička sredina rezultata svih modela (slabi učenici) množenim sa njegovom težinom \n",
    "<div style=\"width:70%;margin:10px auto;\">![boosting_3.png](img/boosting_3.png)</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 3.1. AdaBoost\n",
    "\n",
    "\n",
    "Adaptive boosting ili AdaBoost je jedan od najjednostavnijih *boostring* algoritama. Obično se za modeliranje koriste stabla odluke. Stvaraju se višestruki sekvencijalni modeli, od kojih svaki ispravlja pogreške iz posljednjeg modela. AdaBoost dodjeljuje težine opservacijama koje su pogrešno predviđene, a naknadni model ispravno predviđa te vrijednosti. \n",
    "\n",
    "\n",
    "U nastavku su navedeni koraci za izvođenje AdaBoost algoritma:\n",
    "\n",
    "1. U početku, sve opservacije u skupu podataka dobivaju jednake težine.\n",
    "2. Model je izgrađen na podskupu podataka.\n",
    "3. Koristeći ovaj model, radi se predikcija na cijelom skupu podataka.\n",
    "4. Izračunavaju se pogreške usporedbom predviđanja i stvarnih vrijednosti.\n",
    "5. Prilikom stvaranja sljedećeg modela se opservacijama koje su pogrešno predviđene dodaju veće težine.\n",
    "6. Težine se mogu odrediti pomoću vrijednosti pogreške. Na primjer, veća pogreška -> veća težina dodijeljena opservaciji.\n",
    "7. Taj se postupak ponavlja sve dok se funkcija pogreške ne promijeni ili se ne postigne maksimalno ograničenje broja procjenitelja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82113821138211385"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3442780301954409"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost - kod za regresijski problem\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model = AdaBoostRegressor(random_state=1)\n",
    "model.fit(x_train_r, y_train_r)\n",
    "model.score(x_test_r, y_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Gradient Boosting (GBM)\n",
    "\n",
    "\n",
    "Gradient Boosting ili GBM je još jedan algoritam strojnog učenja koji radi za probleme regresije i klasifikacije. GBM koristi *boosting* tehniku, kombinirajući brojne slabe učenike kako bi oblikovali snažnog učenika. Stabla regresije koji se koriste kao osnovni učenici ima određenu pogrešku, te je svako sljedeće stablo u nizu izgrađeno na pogreškama koje je izračunalo prethodni stablo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82926829268292679"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting (GBM)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model= GradientBoostingClassifier(learning_rate=0.01, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39232465088155677"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting (GBM) - kod za regresijski problem\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model= GradientBoostingRegressor(random_state=1)\n",
    "model.fit(x_train_r, y_train_r)\n",
    "model.score(x_test_r, y_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. XGBoost\n",
    "\n",
    "\n",
    "XGBoost (extreme Gradient Boosting) je napredna implementacija *gradient boosting* algoritma. XGBoost se pokazao kao vrlo učinkovit ML algoritam, široko korišten u natjecanjima strojnog učenja i hackathonima. XGBoost ima visoku prediktivnu snagu i gotovo je 10 puta brži od drugih gradijentnih tehnika. XGBoost također uključuje niz regulacija koje smanjuju *overfitting* i poboljšavaju ukupnu učinkovitost algoritma.\n",
    "\n",
    "XGBoost ima ugrađenu rutinu za obradu nedostajućih vrijednosti tako da prilikom pripreme podataka nije potrebno sređivati nedostajuće vrijednosti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82926829268292679"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(learning_rate=0.01, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42269957094733496"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost - kod za regresijski problem\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(random_state=1)\n",
    "model.fit(x_train_r, y_train_r)\n",
    "model.score(x_test_r, y_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. CatBoost\n",
    "\n",
    "Rad sa kategoričkim varijablama je zamoran proces, osobito ako imate velik broj takvih varijabli. Kada vaše kategorijske varijable imaju previše oznaka (tj. Visoko su kardinalne), izvođenje *one-hot encoding*-a na njima eksponencijalno povećava dimenzionalnost i postaje stvarno teško raditi s skupom podataka.\n",
    "\n",
    "CatBoost se može automatski baviti kategorijskim varijablama i ne zahtijeva opsežnu obradu podataka kao i drugi algoritmi strojnog učenja. Dakle, nije potrebno izvoditi transformaciju kategoričkih varijabli, već je dovoljno učitati podatke, ispraviti nedostajuće vrijednosti i podaci su spremni.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83739837398373984"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(random_seed=1)\n",
    "model.fit(x_train, y_train.astype('category').cat.codes, eval_set=(x_test, y_test.astype('category').cat.codes), verbose=False)\n",
    "model.score(x_test, y_test.astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.221165477328917"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoost - kod za regresijski problem\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(random_seed=1)\n",
    "model.fit(x_train_r, y_train_r, eval_set=(x_test_r, y_test_r), verbose=False)\n",
    "model.score(x_test_r, y_test_r)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
